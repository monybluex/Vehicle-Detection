{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Vehicle Detection.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "g6UGpOjGuhOy",
    "XcWkWEI0psNZ",
    "uZRFMTPOrYeQ"
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6UGpOjGuhOy",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### face detection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "eye_classifier = cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "img = cv2.imread(\"download.jpg\")\n",
    "gray_img= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray_img,1.05,5)\n",
    "eyes= eye_classifier.detectMultiScale(gray_img,1.1,5)\n",
    "\n",
    "for x,y,w,h in faces:\n",
    "\timg = cv2.rectangle(img, (x,y),(x+w,y+h),(255,255,255),3)\n",
    "\n",
    "\tfor ex,ey,ew,eh in eyes:\n",
    "\t\timg = cv2.rectangle(img, (ex,ey),(ex+ew,ey+eh),(255,255,255),3)\n",
    "\n",
    "cv2.imshow(\"Gray\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### motion detection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2,time\n",
    "import numpy as np\n",
    "\n",
    "video= cv2.VideoCapture(\"abc.mp4\")\n",
    "ff= None\n",
    "\n",
    "while True:\n",
    "\tcheck,frame =video.read()\n",
    "\tgray= cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\tgray= cv2.GaussianBlur(gray,(21,21),0)\n",
    "\tif ff is None:\n",
    "\t\tff=gray\n",
    "\t\tcontinue\n",
    "\tdelta_frame = cv2.absdiff(ff,gray)\n",
    "\tthreshold_delta = cv2.threshold (delta_frame,25,255,cv2.THRESH_BINARY)[1]\n",
    "\tthreshold_delta= cv2.dilate(threshold_delta,None,0)\n",
    "\tcnts,_ = cv2.findContours(threshold_delta.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\tfor contour in cnts:\n",
    "\t\tif cv2.contourArea(contour)<1000:\n",
    "\t\t\tcontinue\n",
    "\t\t(x,y,w,h) = cv2.boundingRect(contour)\n",
    "\t\tcv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),3)\n",
    "\t\ttext=\"Activity being carried\"\n",
    "\tcv2.imshow(\"capturingGray\",gray)\n",
    "\tcv2.imshow(\"frame\",frame)\n",
    "\tcv2.imshow('delta',delta_frame)\n",
    "\tcv2.imshow(\"thresh\",threshold_delta)\n",
    "\n",
    "\tkey= cv2.waitKey(24)\n",
    "\tif key == ord('q'):\n",
    "\t\tbreak\n",
    "print(a\t)\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcWkWEI0psNZ"
   },
   "source": [
    "import cv2,time\n",
    "import numpy as np\n",
    "\n",
    "video= cv2.VideoCapture(\"abc.mp4\")\n",
    "ff= None\n",
    "\n",
    "while True:\n",
    "\tcheck,frame =video.read()\n",
    "\tgray= cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\tgray= cv2.GaussianBlur(gray,(21,21),0)\n",
    "\tif ff is None:\n",
    "\t\tff=gray\n",
    "\t\tcontinue\n",
    "\tdelta_frame = cv2.absdiff(ff,gray)\n",
    "\tthreshold_delta = cv2.threshold (delta_frame,25,255,cv2.THRESH_BINARY)[1]\n",
    "\tthreshold_delta= cv2.dilate(threshold_delta,None,0)\n",
    "\tcnts,_ = cv2.findContours(threshold_delta.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\tfor contour in cnts:\n",
    "\t\tif cv2.contourArea(contour)<1000:\n",
    "\t\t\tcontinue\n",
    "\t\t(x,y,w,h) = cv2.boundingRect(contour)\n",
    "\t\tcv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),3)\n",
    "\t\ttext=\"Activity being carried\"\n",
    "\tcv2.imshow(\"capturingGray\",gray)\n",
    "\tcv2.imshow(\"frame\",frame)\n",
    "\tcv2.imshow('delta',delta_frame)\n",
    "\tcv2.imshow(\"thresh\",threshold_delta)\n",
    "\n",
    "\tkey= cv2.waitKey(24)\n",
    "\tif key == ord('q'):\n",
    "\t\tbreak\n",
    "print(a\t)\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AndbeKgbTQiV"
   },
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "eye_classifier = cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "img = cv2.imread(\"download.jpg\")\n",
    "gray_img= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray_img,1.05,5)\n",
    "eyes= eye_classifier.detectMultiScale(gray_img,1.1,5)\n",
    "\n",
    "for x,y,w,h in faces:\n",
    "\timg = cv2.rectangle(img, (x,y),(x+w,y+h),(255,255,255),3)\n",
    "\n",
    "\tfor ex,ey,ew,eh in eyes:\n",
    "\t\timg = cv2.rectangle(img, (ex,ey),(ex+ew,ey+eh),(255,255,255),3)\n",
    "\n",
    "cv2.imshow(\"Gray\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZRFMTPOrYeQ"
   },
   "source": [
    "### motion detection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Dk2dbCWbre9J",
    "outputId": "2ae8f115-49e0-413b-ff6e-6f81992ad587",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    }
   },
   "source": [
    "import cv2,time\n",
    "import numpy as np\n",
    "\n",
    "video= cv2.VideoCapture(\"abc.mp4\")\n",
    "ff= None\n",
    "\n",
    "while True:\n",
    "\tcheck,frame =video.read()\n",
    "\tgray= cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\tgray= cv2.GaussianBlur(gray,(21,21),0)\n",
    "\tif ff is None:\n",
    "\t\tff=gray\n",
    "\t\tcontinue\n",
    "\tdelta_frame = cv2.absdiff(ff,gray)\n",
    "\tthreshold_delta = cv2.threshold (delta_frame,25,255,cv2.THRESH_BINARY)[1]\n",
    "\tthreshold_delta= cv2.dilate(threshold_delta,None,0)\n",
    "\tcnts,_ = cv2.findContours(threshold_delta.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\tfor contour in cnts:\n",
    "\t\tif cv2.contourArea(contour)<1000:\n",
    "\t\t\tcontinue\n",
    "\t\t(x,y,w,h) = cv2.boundingRect(contour)\n",
    "\t\tcv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),3)\n",
    "\t\ttext=\"Activity being carried\"\n",
    "\tcv2.imshow(\"capturingGray\",gray)\n",
    "\tcv2.imshow(\"frame\",frame)\n",
    "\tcv2.imshow('delta',delta_frame)\n",
    "\tcv2.imshow(\"thresh\",threshold_delta)\n",
    "\n",
    "\tkey= cv2.waitKey(24)\n",
    "\tif key == ord('q'):\n",
    "\t\tbreak\n",
    "print(a\t)\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "error",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-11b69d7c4d88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcheck\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mgray\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mgray\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mff\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ]
  }
 ]
}